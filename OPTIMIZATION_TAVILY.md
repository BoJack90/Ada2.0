# Optymalizacja wykorzystania Tavily API

##  KRYTYCZNY PROBLEM
Obecnie system wykonuje **700+ wywoa Tavily API** dla jednego planu treci!

### Rzeczywiste zu偶ycie:
- **4 wywoania** - analiza strony
- **13 wywoa** - research temat贸w
- **16 wywoa** - 4 posty bloga  4 zapytania ka偶dy
- **144 wywoania** - 12 post贸w SM  3 platformy  4 zapytania
- ** 3-4 regeneracje** = **531-708 WYWOA RAZEM!**

Ka偶dy wariant wykonuje WASNY research z 4 zapytaniami zamiast u偶ywa wsp贸lnych danych!

##  PILNA NAPRAWA - Wycz research dla wariant贸w!

### NATYCHMIAST: Wycz Tavily w variant_generation.py
**Plik**: `app/tasks/variant_generation.py` linia 374-456
**Akcja**: ZAKOMENTUJ cay blok researchu lub ustaw `skip_research = True`
```python
# PRZED (linie 374-456):
research_context = ""
try:
    logger.info(f"Starting Tavily research for topic: {topic_title}")
    # ... 80 linii kodu z 4 wywoaniami Tavily ...
    
# PO:
research_context = ""  # Research ju偶 by zrobiony podczas generowania temat贸w!
skip_research = True  # WYCZ TAVILY DLA WARIANTW
```
**Efekt**: Z 700 wywoa spadnie do ~20 wywoa (redukcja 97%!)

## Rozwizania dugoterminowe

### 1. **Cache wsp贸dzielony midzy wariantami** (Redukcja: 95%)
**Problem**: Ka偶dy wariant robi osobny research dla tego samego tematu
**Rozwizanie**: Zr贸b research RAZ per temat, u偶yj dla wszystkich wariant贸w
```python
# W generate_content_variant_task
research_cache_key = f"topic_research_{topic_id}"
if research_cache_key in redis_cache:
    research_data = redis_cache.get(research_cache_key)
else:
    research_data = tavily.research(topic)
    redis_cache.set(research_cache_key, research_data, ttl=7200)  # 2h cache
```

### 2. **Wycz research dla post贸w SM** (Redukcja: 50%)
**Problem**: Kr贸tkie posty SM nie potrzebuj gbokiego researchu
**Rozwizanie**: Research tylko dla blog贸w
```python
if content_type == 'blog':
    research_data = tavily.research(topic)
else:
    research_data = None  # SM u偶ywa tylko kontekstu z super_context
```

### 3. **Batch research zamiast pojedynczych** (Redukcja: 30%)
**Problem**: Osobne wywoania dla ka偶dego aspektu
**Rozwizanie**: Jedno wywoanie z wieloma pytaniami
```python
# Zamiast 4 wywoa dla analizy strony:
all_questions = [
    f"company overview {url}",
    f"industry sector {url}",
    f"services offered {url}",
    f"company values {url}"
]
result = tavily.search(' AND '.join(all_questions), max_results=10)
# Parsuj jeden wynik na 4 kategorie
```

### 4. **Zwiksz cache TTL** (Redukcja: 20%)
**Problem**: Cache 24h, ale plany czsto regenerowane
**Rozwizanie**: 
- Cache analizy strony: 7 dni
- Cache research temat贸w: 3 dni
- Cache og贸lnych trend贸w: 7 dni

### 5. **Warunki pomijania researchu** (Redukcja: 15%)
```python
# Pomi research gdy:
if any([
    'case study' in topic.lower(),  # Case studies u偶ywaj danych wewntrznych
    'zesp贸' in topic.lower(),      # Posty o zespole
    'akson elektro' in topic.lower() and 'sukces' in topic.lower(),  # Wasne sukcesy
]):
    skip_research = True
```

## Implementacja priorytetowa

### Krok 1: Cache wsp贸dzielony (najatwiejszy)
**Plik**: `app/tasks/content_generation.py`
**Funkcja**: `generate_content_variant_task`
**Czas**: 30 min
**Redukcja**: 70% wywoa

### Krok 2: Wycz dla SM
**Plik**: `app/tasks/content_generation.py`  
**Warunek**: `if platform != 'blog'`
**Czas**: 15 min
**Redukcja**: 50% pozostaych

### Krok 3: Batch queries
**Plik**: `app/core/external_integrations.py`
**Funkcja**: `analyze_website`
**Czas**: 1h
**Redukcja**: 30% dla nowych analiz

## Wynik kocowy
Po implementacji:
- Przed: **65 wywoa**
- Po: **8-12 wywoa** (redukcja 80-85%)

## Monitoring
Dodaj licznik wywoa:
```python
# W TavilyIntegration.__init__
self.api_calls_count = 0

# W ka偶dej metodzie wywoujcej API
self.api_calls_count += 1
logger.info(f"Tavily API call #{self.api_calls_count}: {method_name}")
```